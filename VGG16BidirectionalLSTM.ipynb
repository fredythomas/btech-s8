{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"name":"VGG16BidirectionalLSTM.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"-VDTTRgE33VQ"},"source":["from keras.layers import Dense, Flatten, Activation, Dropout, Bidirectional\n","from keras.layers.recurrent import LSTM\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.applications.vgg16 import VGG16\n","from keras.optimizers import SGD\n","from keras import backend as K\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import ModelCheckpoint\n","import os\n","import numpy as np\n","\n","import import_ipynb\n","from VGGFeatureExtractor  import extract_vgg16_features_live, scan_and_extract_vgg16_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-NiD_dR33VW"},"source":["BATCH_SIZE = 64\n","NUM_EPOCHS = 20\n","VERBOSE = 1\n","HIDDEN_UNITS = 512\n","MAX_ALLOWED_FRAMES = 20\n","EMBEDDING_SIZE = 100\n","\n","K.set_image_dim_ordering('tf')\n","\n","\n","def generate_batch(x_samples, y_samples):\n","    num_batches = len(x_samples) // BATCH_SIZE\n","\n","    while True:\n","        for batchIdx in range(0, num_batches):\n","            start = batchIdx * BATCH_SIZE\n","            end = (batchIdx + 1) * BATCH_SIZE\n","            yield np.array(x_samples[start:end]), y_samples[start:end]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tN3-5yIm33Va"},"source":["class VGG16BidirectionalLSTMVideoClassifier(object):\n","    model_name = 'vgg16-bidirectional-lstm'\n","\n","    def __init__(self):\n","        self.num_input_tokens = None\n","        self.nb_classes = None\n","        self.labels = None\n","        self.labels_idx2word = None\n","        self.model = None\n","        self.vgg16_model = None\n","        self.expected_frames = None\n","        self.vgg16_include_top = True\n","        self.config = None\n","\n","    def create_model(self):\n","        model = Sequential()\n","        model.add(Bidirectional(LSTM(units=HIDDEN_UNITS, return_sequences=True),\n","                                input_shape=(self.expected_frames, self.num_input_tokens)))\n","        model.add(Bidirectional(LSTM(10)))\n","        model.add(Dense(512, activation='relu'))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Dense(self.nb_classes))\n","\n","        model.add(Activation('softmax'))\n","\n","        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","        return model\n","\n","    @staticmethod\n","    def get_config_file_path(model_dir_path, vgg16_include_top=None):\n","        if vgg16_include_top is None:\n","            vgg16_include_top = True\n","        if vgg16_include_top:\n","            return model_dir_path + '/' + VGG16BidirectionalLSTMVideoClassifier.model_name + '-config.npy'\n","        else:\n","            return model_dir_path + '/' + VGG16BidirectionalLSTMVideoClassifier.model_name + '-hi-dim-config.npy'\n","\n","    @staticmethod\n","    def get_weight_file_path(model_dir_path, vgg16_include_top=None):\n","        if vgg16_include_top is None:\n","            vgg16_include_top = True\n","        if vgg16_include_top:\n","            return model_dir_path + '/' + VGG16BidirectionalLSTMVideoClassifier.model_name + '-weights.h5'\n","        else:\n","            return model_dir_path + '/' + VGG16BidirectionalLSTMVideoClassifier.model_name + '-hi-dim-weights.h5'\n","\n","    @staticmethod\n","    def get_architecture_file_path(model_dir_path, vgg16_include_top=None):\n","        if vgg16_include_top is None:\n","            vgg16_include_top = True\n","        if vgg16_include_top:\n","            return model_dir_path + '/' + VGG16BidirectionalLSTMVideoClassifier.model_name + '-architecture.json'\n","        else:\n","            return model_dir_path + '/' + VGG16BidirectionalLSTMVideoClassifier.model_name + '-hi-dim-architecture.json'\n","    \n","    \n","    \n","\n","    def load_model(self, config_file_path, weight_file_path):\n","        if os.path.exists(config_file_path):\n","            print('loading configuration from ', config_file_path)\n","        else:\n","            raise ValueError('cannot locate config file {}'.format(config_file_path))\n","\n","        config = np.load(config_file_path,allow_pickle=True).item()\n","        self.num_input_tokens = config['num_input_tokens']\n","        self.nb_classes = config['nb_classes']\n","        self.labels = config['labels']\n","        self.expected_frames = config['expected_frames']\n","        self.vgg16_include_top = config['vgg16_include_top']\n","        self.labels_idx2word = dict([(idx, word) for word, idx in self.labels.items()])\n","        self.config = config\n","\n","        self.model = self.create_model()\n","        if os.path.exists(weight_file_path):\n","            print('loading network weights from ', weight_file_path)\n","        else:\n","            raise ValueError('cannot local weight file {}'.format(weight_file_path))\n","\n","        self.model.load_weights(weight_file_path)\n","\n","        print('build vgg16 with pre-trained model')\n","        #vgg16_model = VGG16(include_top=self.vgg16_include_top, weights='imagenet')\n","        #K.set_image_dim_ordering(\"th\")\n","        vgg16_model = VGG16(include_top=self.vgg16_include_top, weights='Models/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n","        #vgg16_model = self.VGG_16('Models/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n","        vgg16_model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n","        self.vgg16_model = vgg16_model\n","\n","    def predict(self, video_file_path):\n","        x = extract_vgg16_features_live(self.vgg16_model, video_file_path)\n","        print(\"VGG16 Features Extraction Completed...\")\n","        print(\"Model Prediction Started...\")\n","        frames = x.shape[0]\n","        if frames > self.expected_frames:\n","            x = x[0:self.expected_frames, :]\n","        elif frames < self.expected_frames:\n","            temp = np.zeros(shape=(self.expected_frames, x.shape[1]))\n","            temp[0:frames, :] = x\n","            x = temp\n","        predicted_class = np.argmax(self.model.predict(np.array([x]))[0])\n","        predicted_label = self.labels_idx2word[predicted_class]\n","        return predicted_label\n","\n","    def fit(self, data_dir_path, model_dir_path, vgg16_include_top=True, data_set_name='UCF-101', test_size=0.3,\n","            random_state=42):\n","\n","        self.vgg16_include_top = vgg16_include_top\n","\n","        config_file_path = self.get_config_file_path(model_dir_path, vgg16_include_top)\n","        weight_file_path = self.get_weight_file_path(model_dir_path, vgg16_include_top)\n","        architecture_file_path = self.get_architecture_file_path(model_dir_path, vgg16_include_top)\n","\n","        self.vgg16_model = VGG16(include_top=self.vgg16_include_top, weights='imagenet')\n","        self.vgg16_model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","        feature_dir_name = data_set_name + '-VGG16-Features'\n","        if not vgg16_include_top:\n","            feature_dir_name = data_set_name + '-VGG16-HiDimFeatures'\n","        max_frames = 0\n","        self.labels = dict()\n","        x_samples, y_samples = scan_and_extract_vgg16_features(data_dir_path,\n","                                                               output_dir_path=feature_dir_name,\n","                                                               model=self.vgg16_model,\n","                                                               data_set_name=data_set_name)\n","        self.num_input_tokens = x_samples[0].shape[1]\n","        frames_list = []\n","        for x in x_samples:\n","            frames = x.shape[0]\n","            frames_list.append(frames)\n","            max_frames = max(frames, max_frames)\n","        self.expected_frames = int(np.mean(frames_list))\n","        print('max frames: ', max_frames)\n","        print('expected frames: ', self.expected_frames)\n","        for i in range(len(x_samples)):\n","            x = x_samples[i]\n","            frames = x.shape[0]\n","            if frames > self.expected_frames:\n","                x = x[0:self.expected_frames, :]\n","                x_samples[i] = x\n","            elif frames < self.expected_frames:\n","                temp = np.zeros(shape=(self.expected_frames, x.shape[1]))\n","                temp[0:frames, :] = x\n","                x_samples[i] = temp\n","        for y in y_samples:\n","            if y not in self.labels:\n","                self.labels[y] = len(self.labels)\n","        print(self.labels)\n","        for i in range(len(y_samples)):\n","            y_samples[i] = self.labels[y_samples[i]]\n","\n","        self.nb_classes = len(self.labels)\n","\n","        y_samples = np_utils.to_categorical(y_samples, self.nb_classes)\n","\n","        config = dict()\n","        config['labels'] = self.labels\n","        config['nb_classes'] = self.nb_classes\n","        config['num_input_tokens'] = self.num_input_tokens\n","        config['expected_frames'] = self.expected_frames\n","        config['vgg16_include_top'] = self.vgg16_include_top\n","\n","        self.config = config\n","\n","        np.save(config_file_path, config)\n","\n","        model = self.create_model()\n","        open(architecture_file_path, 'w').write(model.to_json())\n","\n","        Xtrain, Xtest, Ytrain, Ytest = train_test_split(x_samples, y_samples, test_size=test_size,\n","                                                        random_state=random_state)\n","\n","        train_gen = generate_batch(Xtrain, Ytrain)\n","        test_gen = generate_batch(Xtest, Ytest)\n","\n","        train_num_batches = len(Xtrain) // BATCH_SIZE\n","        test_num_batches = len(Xtest) // BATCH_SIZE\n","\n","        checkpoint = ModelCheckpoint(filepath=weight_file_path, save_best_only=True)\n","        history = model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n","                                      epochs=NUM_EPOCHS,\n","                                      verbose=1, validation_data=test_gen, validation_steps=test_num_batches,\n","                                      callbacks=[checkpoint])\n","        model.save_weights(weight_file_path)\n","\n","        return history\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9FCJL1633Ve"},"source":[""],"execution_count":null,"outputs":[]}]}