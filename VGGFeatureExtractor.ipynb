{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"colab":{"name":"VGGFeatureExtractor.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"r4Ml3Fgwd3-m","colab_type":"code","outputId":"50a9d7a4-4a4d-4204-eb33-baa5913341c3","executionInfo":{"status":"ok","timestamp":1584532052340,"user_tz":-330,"elapsed":6468,"user":{"displayName":"Sahaj d","photoUrl":"","userId":"13950582096679244504"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import cv2\n","import os\n","import numpy as np\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.preprocessing.image import img_to_array\n","from keras.optimizers import SGD"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"TOcCTS0Rd3-w","colab_type":"code","colab":{}},"source":["MAX_NB_CLASSES = 5\n","\n","\n","def extract_vgg16_features_live(model, video_input_file_path):\n","    print('Extracting frames from video: ', video_input_file_path)\n","    vidcap = cv2.VideoCapture(video_input_file_path)\n","    success, image = vidcap.read()\n","    features = []\n","    success = True\n","    count = 0\n","    while success:\n","        vidcap.set(cv2.CAP_PROP_POS_MSEC, (count * 1000))  # added this line\n","        success, image = vidcap.read()\n","        # print('Read a new frame: ', success)\n","        if success:\n","            img = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n","            input = img_to_array(img)\n","            input = np.expand_dims(input, axis=0)\n","            input = preprocess_input(input)\n","            feature = model.predict(input).ravel()\n","            features.append(feature)\n","            count = count + 1\n","    unscaled_features = np.array(features)\n","    return unscaled_features\n","\n","\n","def extract_vgg16_features(model, video_input_file_path, feature_output_file_path):\n","    if os.path.exists(feature_output_file_path):\n","        return np.load(feature_output_file_path)\n","    count = 0\n","    print('Extracting frames from video: ', video_input_file_path)\n","    vidcap = cv2.VideoCapture(video_input_file_path)\n","    success, image = vidcap.read()\n","    features = []\n","    success = True\n","    while success:\n","        vidcap.set(cv2.CAP_PROP_POS_MSEC, (count * 1000))  # added this line\n","        success, image = vidcap.read()\n","        # print('Read a new frame: ', success)\n","        if success:\n","            img = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n","            input = img_to_array(img)\n","            input = np.expand_dims(input, axis=0)\n","            input = preprocess_input(input)\n","            feature = model.predict(input).ravel()\n","            features.append(feature)\n","            count = count + 1\n","    unscaled_features = np.array(features)\n","    np.save(feature_output_file_path, unscaled_features)\n","    return unscaled_features\n","\n","\n","def scan_and_extract_vgg16_features(data_dir_path, output_dir_path, model=None, data_set_name=None):\n","    if data_set_name is None:\n","        data_set_name = 'UCF-101'\n","\n","    #input_data_dir_path = data_dir_path + '/' + data_set_name\n","    input_data_dir_path = data_dir_path\n","    output_feature_data_dir_path = data_dir_path + '/' + output_dir_path\n","\n","    if model is None:\n","        model = VGG16(include_top=True, weights='imagenet')\n","        model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n","    \n","    if not os.path.exists(output_feature_data_dir_path):\n","        os.makedirs(output_feature_data_dir_path)\n","\n","    y_samples = []\n","    x_samples = []\n","\n","    dir_count = 0\n","    for f in os.listdir(input_data_dir_path):\n","        file_path = input_data_dir_path + os.path.sep + f\n","        if not os.path.isfile(file_path):\n","            output_dir_name = f\n","            output_dir_path = output_feature_data_dir_path + os.path.sep + output_dir_name\n","            if not os.path.exists(output_dir_path):\n","                os.makedirs(output_dir_path)\n","            dir_count += 1\n","            for ff in os.listdir(file_path):\n","                video_file_path = file_path + os.path.sep + ff\n","                output_feature_file_path = output_dir_path + os.path.sep + ff.split('.')[0] + '.npy'\n","                x = extract_vgg16_features(model, video_file_path, output_feature_file_path)\n","                y = f\n","                y_samples.append(y)\n","                x_samples.append(x)\n","\n","        if dir_count == MAX_NB_CLASSES:\n","            break\n","\n","    return x_samples, y_samples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cYTz7SMd3-2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}